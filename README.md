```markdown
# ğŸš€ Local ChatGPT â€” Powered by Ollama + Python (Streaming + PDF RAG + Embeddings + FAISS)

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Flask](https://img.shields.io/badge/Flask-Web%20Framework-green)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-orange)
![FAISS](https://img.shields.io/badge/FAISS-Vector%20Search-purple)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Stars](https://img.shields.io/github/stars/manojrammurthy/ollama-local-chatgpt?style=social)
ğŸš€ Overview

This project is a local AI research and development platform that combines:

ChatGPT-like local LLM chat interface

Streamed responses

Model selector

PDF-aware RAG mode

Source citations

Session history

Embedding Explorer (Full Suite)

Generate embeddings

PCA 2D

PCA 3D

Cosine similarity / L2 / dot product

Difference heatmap

Batch embedding

FAISS-based persistent vector index

Similarity matrix

KMeans clustering visualization

PDF Intelligence (RAG)

Upload PDFs

Auto chunking

Embedding + FAISS indexing

Ask questions filtered by PDF

Page-aware source highlighting

Delete + rebuild index cleanly

This tool is ideal for:

Building RAG systems

Understanding embeddings

Debugging semantic similarity

Learning ML engineering

Explaining LLM internals

Academic demonstrations

ğŸ§° Features
ğŸ§  Local ChatGPT (Ollama UI)

âœ” Stream chat responses
âœ” Switch models instantly
âœ” PDF mode toggle
âœ” Multi-PDF selection
âœ” Extracted page sources
âœ” Typing animations
âœ” Clean dark UI

ğŸ” Embedding Explorer â€” Advanced Tools
ğŸ“Œ 1. Generate Embeddings

Instant vector preview

First 30 dims

PCA (2D scatter)

Dimension display

ğŸ”— 2. Compare Two Text Embeddings

Cosine similarity

L2 distance

Dot product

PCA 2D comparison

PCA 3D visualization (Plotly)

Dim-wise difference heatmap

ğŸ§¬ 3. Cluster Explorer

Batch embed any texts

Persist in FAISS

KMeans clustering

PCA 2D cluster plot

ğŸ§© 4. Similarity Matrix

Interactive cosine similarity grid

Values + color-coded cells

Scales based on semantic closeness

ğŸ“š PDF RAG Engine

âœ” Upload any PDF
âœ” Extract + chunk content
âœ” Auto-embed with nomic-embed-text
âœ” Build FAISS index
âœ” Query with selected PDFs
âœ” Return exact pages as sources
âœ” Delete PDFs + clean index

ğŸ§± Tech Stack

Backend: Python, Flask

LLM Runtime: Ollama (phi3, nomic-embed-text)

Vector Index: FAISS

Math/ML: NumPy, scikit-learn

Frontend: Tailwind CSS, Chart.js, Plotly

PDF: PyMuPDF (fitz)

Everything runs offline, local, and fast.

ğŸ“¦ Project Structure
ollama-local-chatgpt/
â”‚â”€â”€ app.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ uploaded_pdfs/
â”‚â”€â”€ explorer_index.faiss
â”‚â”€â”€ explorer_meta.json
â”‚â”€â”€ templates/
â”‚     â”œâ”€â”€ index.html
â”‚     â””â”€â”€ embedding_explorer.html
â”‚â”€â”€ static/
â””â”€â”€ README.md

â–¶ï¸ Installation & Usage
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Start Ollama
ollama serve

3ï¸âƒ£ Pull required models
ollama pull phi3
ollama pull nomic-embed-text

4ï¸âƒ£ Run server
python app.py

5ï¸âƒ£ Open in browser

â¡ http://localhost:5000

ğŸ”¥ Roadmap
Phase 1 â€” Embedding Visualizations

âœ” Completed

Phase 2 â€” Financial Embedding Model

â³ Next

Phase 3 â€” Fine-tuning embeddings

ğŸ¯ Coming soon

Phase 4 â€” Multi-user AI dashboard (Django + Postgres vector DB)

ğŸ”¥ Future milestone

Phase 5 â€” Desktop version (Electron / Tauri)

ğŸ–¥ï¸ Planned
